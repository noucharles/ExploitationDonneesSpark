package fr.binome.writer;

import lombok.RequiredArgsConstructor;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SaveMode;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.Map;
import java.util.function.Consumer;

@RequiredArgsConstructor
public class ResultWriter implements Consumer<Dataset<Row>> {
    private final String outputPathStr;

    @Override
    public void accept(Dataset<Row> rows) {
        Path outputPath = Paths.get(outputPathStr);

        try {
            Files.createDirectories(outputPath);
            rows.coalesce(1).write().mode(SaveMode.Overwrite).csv(outputPathStr);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}